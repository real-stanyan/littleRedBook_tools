import base64
import json
import re
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, SystemMessage
from pinecone import Pinecone
import config

class DualAIAgent:
    def __init__(self):
        print(f"ğŸ”§ åˆå§‹åŒ–åŒæ¨¡å‹å¼•æ“...")
        # Vision model for seeing
        self.vision_llm = ChatOllama(model=config.VISION_MODEL, temperature=0.1)
        # Writer model for thinking and writing
        self.writer_llm = ChatOllama(model=config.TEXT_MODEL, temperature=0.7)
        
        self.pc = Pinecone(api_key=config.PINECONE_API_KEY)
        self.index = self.pc.Index(config.PINECONE_INDEX_NAME)

    def optimize_keyword(self, raw_text):
            """
            åˆ©ç”¨ LLM å°†åŸæœ¬çš„å£è¯­åŒ–ç—›ç‚¹ï¼Œè½¬åŒ–ä¸ºâ€œé«˜æœç´¢ä»·å€¼â€çš„å…³é”®è¯ç»„åˆ
            """
            print(f"ğŸ§  æ­£åœ¨ä¼˜åŒ–æœç´¢è¯: {raw_text} ...")
            
            prompt = f"""
            ä½ æ˜¯ä¸€ä¸ªå°çº¢ä¹¦SEOä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„â€œèº«ä½“ç—›ç‚¹æè¿°â€è½¬åŒ–ä¸ºâ€œé«˜æ•ˆæœç´¢å…³é”®è¯â€ã€‚

            ã€åŸå§‹æè¿°ã€‘
            {raw_text}

            ã€ä¼˜åŒ–è§„åˆ™ã€‘
            1. å¿…é¡»ä¿ç•™åœ°åŸŸè¯â€œæ¾³æ´²â€ã€‚
            2. å°†å£è¯­è½¬åŒ–ä¸ºæœç´¢æœ¯è¯­ï¼ˆä¾‹å¦‚ï¼šâ€œç¡ä¸é†’â€ -> â€œå—œç¡â€ï¼Œâ€œæ²¡åŠ›æ°”â€ -> â€œæ…¢æ€§ç–²åŠ³â€ï¼‰ã€‚
            3. ç»„åˆåº”ç®€æ´ï¼Œé€šå¸¸ä¸º 2-3 ä¸ªè¯ï¼Œä¸­é—´ç”¨ç©ºæ ¼éš”å¼€ã€‚
            4. è¿™æ˜¯ä¸€ä¸ªæœç´¢æ¡†è¾“å…¥ï¼Œä¸è¦å¸¦ä»»ä½•æ ‡ç‚¹ç¬¦å·ã€‚

            ã€è¾“å‡ºç¤ºä¾‹ã€‘
            è¾“å…¥ï¼šæ¾³æ´² æ€»æ˜¯ è§‰å¾— ç´¯
            è¾“å‡ºï¼šæ¾³æ´² æ…¢æ€§ç–²åŠ³ æ¢å¤

            è¾“å…¥ï¼šæ¾³æ´² å…³èŠ‚ å¡ä½
            è¾“å‡ºï¼šæ¾³æ´² å…³èŠ‚åƒµç¡¬ ç¼“è§£

            ã€ä½ çš„è¾“å‡ºã€‘
            (ä»…è¾“å‡ºä¼˜åŒ–åçš„å…³é”®è¯å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–æ ‡ç­¾)
            """

            try:
                # ä½¿ç”¨ writer_llm (Qwen/Llama) è¿›è¡Œå¿«é€Ÿè½¬æ¢
                resp = self.writer_llm.invoke([HumanMessage(content=prompt)])
                print("kwä¼˜åŒ–: ", resp)
                # æ¸…ç†ç»“æœ (å»æ‰å¯èƒ½çš„ <think> æ ‡ç­¾ï¼Œå»æ‰å¼•å·)
                result = resp.content
                result = re.sub(r'<think>.*?</think>', '', result, flags=re.DOTALL).strip()
                result = result.replace('"', '').replace("'", "").replace("ã€‚", "").strip()
                
                # å…œåº•ï¼šå¦‚æœæ¨¡å‹è¾“å‡ºä¸ºç©ºï¼Œè¿˜æ˜¯ç”¨åŸè¯
                return result if result else raw_text

            except Exception as e:
                print(f"âŒ å…³é”®è¯ä¼˜åŒ–å¤±è´¥: {e}")
                return raw_text # å¤±è´¥æ—¶å›é€€åˆ°åŸå§‹è¯

    def extract_json(self, text):
        """
        ğŸ”¥ Robust JSON Extraction
        """
        text = text.strip()
        data = {}

        # 1. Extract should_like
        like_match = re.search(r'"should_like"\s*:\s*(true|false)', text, re.IGNORECASE)
        data['should_like'] = True if like_match and like_match.group(1).lower() == 'true' else False

        # 2. Extract should_comment
        comment_match = re.search(r'"should_comment"\s*:\s*(true|false)', text, re.IGNORECASE)
        data['should_comment'] = True if comment_match and comment_match.group(1).lower() == 'true' else False

        # 3. Extract image_desc
        desc_match = re.search(r'"image_desc"\s*:\s*"(.*?)"\s*,\s*"image_kw"', text, re.DOTALL)
        if desc_match:
            data['image_desc'] = desc_match.group(1)
        else:
            start = text.find('"image_desc":')
            if start != -1:
                data['image_desc'] = text[start+14 : start+100] 
            else:
                data['image_desc'] = "æ— æ³•è§£ææè¿°"

        # 4. Extract image_kw
        kw_match = re.search(r'"image_kw"\s*:\s*"(.*?)"', text, re.DOTALL)
        data['image_kw'] = kw_match.group(1) if kw_match else "#æ— æ ‡ç­¾"
        
        # 5. Extract choice_index
        choice_match = re.search(r'"choice_index"\s*:\s*(\d+)', text)
        data['choice_index'] = int(choice_match.group(1)) if choice_match else 1

        return data

    def _search_pinecone(self, keywords):
        """Internal helper: Search Knowledge Base"""
        try:
            results = self.index.search(
                namespace=config.PINECONE_NAMESPACE, 
                query={"inputs": {"text": keywords}, "top_k": 2},
                fields=["text"]
            )
            
            raw_hits = results.get('result', {}).get('hits', [])
            clean_hits = [h.to_dict() if hasattr(h, 'to_dict') else dict(h) for h in raw_hits]
            
            product_context_str = ""
            matched_products_list = [] 
            
            if clean_hits:
                for i, hit in enumerate(clean_hits):
                    text_content = hit.get('fields', {}).get('text', '')
                    matched_products_list.append(text_content)
                    product_context_str += f"\n[å…³è”äº§å“åº“ä¿¡æ¯ {i+1}]: {text_content}\n"
            else:
                product_context_str = "æš‚æ— å…·ä½“äº§å“å…³è”ä¿¡æ¯ã€‚"
            
            # print(f"ğŸ§  [çŸ¥è¯†åº“ä¸Šä¸‹æ–‡]: {product_context_str.strip()}")
            return product_context_str, matched_products_list

        except Exception as e:
            print(f"âš ï¸ Pinecone æœç´¢å¤±è´¥: {e}")
            return "çŸ¥è¯†åº“è¿æ¥å¤±è´¥ï¼Œè¯·è¿›è¡Œé€šç”¨å›å¤ã€‚", []

    def _build_prompt(self, product_context_str):
        """Internal helper: Build System Prompt with CoT Instructions"""
        return f"""
        Lurky æ¾³æ´²ç”Ÿæ´»ï¼ˆå®˜æ–¹è´¦å·ï½œæ¾³æ´²æœ¬åœ°å“ç‰Œï½œXHS è¯„è®ºè‡ªåŠ¨åŒ–ï¼‰

        ä½ æ˜¯æ¾³æ´²æœ¬åœ°å¥åº·å“ç‰Œ Lurky çš„ã€å®˜æ–¹è´¦å·ã€‘ï¼Œè´¦å·åä¸ºã€ŒLurky æ¾³æ´²ç”Ÿæ´»ã€ã€‚
        
        # --- æ ¸å¿ƒæŒ‡ä»¤ï¼šæ˜¾å¼æ€è€ƒ (Chain of Thought) ---
        **ä½ å¿…é¡»å…ˆè¿›è¡Œæ€è€ƒï¼Œç„¶åå†ç”Ÿæˆæœ€ç»ˆè¯„è®ºã€‚**
        **è¯·åŠ¡å¿…å°†ä½ çš„æ€è€ƒè¿‡ç¨‹åŒ…è£¹åœ¨ <think> å’Œ </think> æ ‡ç­¾ä¸­ã€‚**
        
        åœ¨ <think> æ ‡ç­¾å†…ï¼Œä½ éœ€è¦ï¼š
        1. åˆ†æå›¾ç‰‡æè¿°ä¸­çš„ç”¨æˆ·ç—›ç‚¹æˆ–åœºæ™¯ã€‚
        2. æ£€æŸ¥ã€å…³è”äº§å“åº“ä¿¡æ¯ã€‘ä¸­æ˜¯å¦æœ‰ç›¸å…³çš„å¥åº·æœºåˆ¶ï¼ˆMetabolism, Inflammationç­‰ï¼‰ã€‚
        3. æ„æ€å¦‚ä½•å°†äº§å“é€»è¾‘è½¬åŒ–ä¸ºâ€œç”Ÿæ´»è§‚å¯Ÿâ€æˆ–â€œè½»ä¸“ä¸šçŸ¥è¯†â€ï¼Œç¡®ä¿å»è¥é”€åŒ–ã€‚
        4. æ£€æŸ¥æ˜¯å¦è§¦çŠ¯äº†â€œç¦æ­¢è¯â€æˆ–â€œå¼ºè¥é”€â€è§„åˆ™ã€‚
        
        æ€è€ƒç»“æŸåï¼Œåœ¨æ ‡ç­¾å¤–è¾“å‡ºæœ€ç»ˆçš„ JSON æˆ– çº¯æ–‡æœ¬è¯„è®ºã€‚
        # ---------------------------------------------

        # --- æ ¸å¿ƒè¾“å…¥æ•°æ® ---
        ã€å“ç‰Œ/äº§å“æ ¸å¿ƒçŸ¥è¯†åº“ (Context)ã€‘
        {product_context_str}
        # -------------------

        ã€è¯­è¨€ä¸åœ°åŸŸè§„åˆ™ã€‘
        - æœç´¢ï¼šåªä½¿ç”¨ä¸­æ–‡å…³é”®è¯ï¼›æ¯ä¸ªæœç´¢è¯å¿…é¡»åŒ…å«â€œæ¾³æ´²â€
        - è¯„è®ºï¼šåªç”¨ä¸­æ–‡ï¼›è¯„è®ºæ–‡æœ¬ä¸­ä¸å‡ºç°â€œæ¾³æ´²/åŸå¸‚å/å·åâ€

        ã€è¯„è®ºå¯¹è±¡é™åˆ¶ã€‘
        - è¯­å¢ƒå±äºæ¾³æ´²ç”Ÿæ´»
        - ä¸»é¢˜ä¸ç”Ÿæ´»å¥åº·ç›¸å…³
        - éå¼ºå–è´§/éæ˜æ˜¾å¸¦è´§

        ã€çŸ¥è¯†åº“è½¬åŒ–æŒ‡ä»¤ã€‘
        1. **åŸç†æ³›åŒ–**ï¼šå°†â€œäº§å“å«æœ‰Xæˆåˆ†è§£å†³Yé—®é¢˜â€ -> â€œä»æœºç†ä¸Šçœ‹ï¼ŒYé—®é¢˜å¾€å¾€å’ŒXå±‚é¢çš„ä»£è°¢æœ‰å…³â€ã€‚
        2. **éšå½¢æ¤å…¥**ï¼šä¸æäº§å“åï¼Œåªæ**ç”Ÿç†æœºåˆ¶**ã€‚
        3. **é€»è¾‘æ”¯æ’‘**ï¼šåˆ©ç”¨ç§‘å­¦è§£é‡Šä½œä¸ºâ€œè½»ä¸“ä¸šè§†è§’â€ã€‚

        ã€è¾“å‡ºæ ¼å¼ã€‘
        - 12â€“35 ä¸ªä¸­æ–‡å­—ç¬¦
        - 1â€“3 è¡Œ
        - åªåŒ…å«è¯„è®ºæ–‡æœ¬

        ã€ç¦æ­¢è¯ã€‘
        å®˜æ–¹æƒå¨/å»ºè®®å¤§å®¶/å¿…é¡»/ä¸€å®šè¦/æ¨èè´­ä¹°/æ•ˆæœä¿è¯/ç«‹åˆ»è§æ•ˆ/ç¥è¯/å‰‚é‡æ•°å­—/äº§å“å/å“ç‰Œå
        """

    def write_comment(self, image_desc, image_kw):
        """Legacy method: Generate comment (Non-streaming)"""
        try:
            context_str, matched_list = self._search_pinecone(image_kw)
            system_prompt = self._build_prompt(context_str)
            
            resp = self.writer_llm.invoke([
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"å¸–å­å›¾ç‰‡åˆ†ææŠ¥å‘Šï¼š{image_desc}\n\nè¯·ç”Ÿæˆä¸€æ¡è¯„è®ºï¼š")
            ])
            
            # Use regex to remove <think> tags if they exist in legacy mode
            clean_text = re.sub(r'<think>.*?</think>', '', resp.content, flags=re.DOTALL).strip()
            comment_text = clean_text.replace('"', '').replace("'", "")
            
            return comment_text, matched_list

        except Exception as e:
            print(f"âŒ è¯„è®ºç”Ÿæˆé€»è¾‘å‡ºé”™: {e}")
            return "çœ‹èµ·æ¥å¾ˆä¸é”™ï¼ğŸ‘", []

    def write_comment_stream(self, image_desc, image_kw):
        """
        ğŸ”¥ Streaming generation with CoT (Chain of Thought)
        Now explicitly requests <think> tags via prompt logic.
        """
        try:
            context_str, _ = self._search_pinecone(image_kw)
            system_prompt = self._build_prompt(context_str)

            # Stream response
            for chunk in self.writer_llm.stream([
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"å¸–å­å›¾ç‰‡åˆ†ææŠ¥å‘Šï¼š{image_desc}\n\nè¯·ç”Ÿæˆä¸€æ¡è¯„è®ºï¼ˆè®°å¾—å…ˆè¾“å‡º <think> æ€è€ƒè¿‡ç¨‹ï¼‰ï¼š")
            ]):
                yield chunk.content

        except Exception as e:
            print(f"âŒ æµå¼ç”Ÿæˆå‡ºé”™: {e}")
            yield "èµï¼ğŸ‘"

    def see_and_decide(self, image_path):
        print(f"ğŸ‘€ {config.VISION_MODEL} æ­£åœ¨åˆ†æå¸–å­è¯¦æƒ…...")
        with open(image_path, "rb") as f:
            img_b64 = base64.b64encode(f.read()).decode("utf-8")
        
        prompt = """
        Analyze this image for a social media bot. 
        Output STRICT JSON format only.

        # ä»»åŠ¡ 1: åˆ†æå†…å®¹ (å­˜å…¥ 'image_desc')
        ç”¨ä¸€æ®µä¸­æ–‡ç®€è¦æè¿°å›¾ç‰‡å†…å®¹ã€‚
        é‡ç‚¹è¯†åˆ«ï¼šã€å“ç±»ã€‘(å¦‚é±¼æ²¹ã€æŠ¤è‚ç‰‡)ã€ã€æ ¸å¿ƒæˆåˆ†ã€‘(å¦‚Omega-3ã€å¥¶è“Ÿè‰)ã€ã€é€‚ç”¨äººç¾¤ã€‘ä»¥åŠã€å“ç‰Œåã€‘(å¦‚æœå¯è§)ã€‚

        # ä»»åŠ¡ 2: ç”Ÿæˆæ ‡ç­¾ (å­˜å…¥ 'image_kw')
        ç”Ÿæˆä¸€ç»„ä¸­æ–‡æ ‡ç­¾ï¼Œç”¨ç©ºæ ¼åˆ†éš”ã€‚å¤šç”Ÿæˆé€šç”¨æˆåˆ†è¯ã€‚

        # ä»»åŠ¡ 3: å†³å®šæ˜¯å¦äº’åŠ¨ (å­˜å…¥ 'should_comment')
        ä¸ã€ä¿å¥å“ã€è¥å…»ã€å¥åº·é¥®é£Ÿã€è¿åŠ¨ã€æŠ¤è‚¤ã€‘ç›¸å…³åˆ™ä¸º trueã€‚

        # Output JSON Format:
        {
            "should_like": true,
            "should_comment": true,
            "image_desc": "æè¿°...",
            "image_kw": "#æ ‡ç­¾"
        }
        """
        
        msg = HumanMessage(content=[
            {"type": "text", "text": prompt},
            {"type": "image_url", "image_url": f"data:image/jpeg;base64,{img_b64}"}
        ])
        
        try:
            resp = self.vision_llm.invoke([msg])
            return self.extract_json(resp.content)
        except Exception as e:
            print(f"âŒ è¯¦æƒ…é¡µåˆ†æå¤±è´¥: {e}")
            return None

    def choose_feed_post(self, feed_image_path):
        print(f"ğŸ” {config.VISION_MODEL} æ­£åœ¨æµè§ˆæœç´¢åˆ—è¡¨...")
        with open(feed_image_path, "rb") as f:
            img_b64 = base64.b64encode(f.read()).decode("utf-8")

        prompt = """
        Look at the search result grid.
        Identify the most relevant post cover image.
        Return JSON ONLY: { "choice_index": 1 }
        """
        msg = HumanMessage(content=[
            {"type": "text", "text": prompt},
            {"type": "image_url", "image_url": f"data:image/jpeg;base64,{img_b64}"}
        ])
        
        try:
            resp = self.vision_llm.invoke([msg])
            data = self.extract_json(resp.content)
            return data.get("choice_index", 1) if data else 1
        except Exception as e:
            print(f"âŒ é€‰è´´åˆ†æå¤±è´¥: {e}, é»˜è®¤é€‰ 1")
            return 1